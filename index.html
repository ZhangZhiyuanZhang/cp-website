<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Learning Canonical 3D Representation for Equivariant Policy">
  <meta name="keywords" content="Equivariance, Imitation Learning, 3D Vision">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://zhangzhiyuanzhang.github.io/personal_website/">Zhiyuan Zhang</a><sup>1,*</sup>,
            </span>
            <span class="author-block">
              <a href="https://zhengtongxu.github.io/website/">Zhengtong Xu</a><sup>1,*</sup>,
            </span>
            <span class="author-block">
              <a href="">Jai Nanda Lakamsani</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.purduemars.com/">Yu She</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
            <span class="author-block"><sup>1</sup>Purdue University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.18474"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Arxiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1fKU6Cs5frtCxBv3SxwQF2hUcB0vKy1US/view?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <span class="link-block">
                <span class="button is-normal is-rounded is-light" disabled>
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                </span>
              </span>
              <span class="link-block">
                <span class="button is-normal is-rounded is-light" disabled>
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data (Coming Soon)</span>
                </span>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>  


<section class="section">
  <div class="container is-max-desktop">
    <!-- Teaser. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Teaser</h2>
        <div class="content has-text-centered">
          <video id="Teaser" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/Teaser.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            Canonical Policy enables vision-conditioned policies to generalize across object appearances and viewpoints by learning canonical 3D representations, with improved sample efficiency.
          </p>
        </div>
      </div>
    </div>
    <!--/ Teaser. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-centered">
          <img id="pipline" src="./static/images/Pipeline.svg" alt="First Page Image" width="100%">
        </div>
        <div class="content has-text-justified">
          <p>
            We introduce canonical policy, a principled framework for 3D equivariant imitation learning that unifies point cloud observations through a canonical representation. Built upon a rigorous theory of 3D canonical mappings, our method enables end-to-end learning of spatially equivariant policies from demonstrations. By leveraging geometric consistency through canonicalization and the expressiveness of generative policy models, such as diffusion models, canonical policy improves generalization and data efficiency in imitation learning.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<!-- Simulation Benchmark Videos Section -->
<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Simulation Benchmark</h2>
    <!-- Space for text above videos -->
    <div class="content has-text-justified">
      <p class="has-text-centered">
        We benchmarked Canonical Policy and several point cloud baselines across 12 simulation tasks. Canonical policy consistently outperforms all baselines, achieving an average task success improvement of 18%.
      </p>
    </div>

    <!-- First Row: 6 Non-metaworld Videos -->
    <div class="columns is-multiline is-centered">
      <!-- stack video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="stack-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/stack.mp4" type="video/mp4">
          </video>
          <p class="caption">Stack D1<sup>1</sup></p>
        </div>
      </div>
      
      <!-- mug video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="mug-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/mug_cleanup.mp4" type="video/mp4">
          </video>
          <p class="caption">Mug Cleanup D1<sup>1</sup></p>
        </div>
      </div>
      
      <!-- Nut Assembly D0 video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="tool-hang-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/nut_assembly.mp4" type="video/mp4">
          </video>
          <p class="caption">Nut Assembly D0<sup>1</sup></p>
        </div>
      </div>
      
      <!-- Stack Three D1 video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="stack_three-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/stack_three.mp4" type="video/mp4">
          </video>
          <p class="caption">Stack Three D1<sup>1</sup></p>
        </div>
      </div>
      
      <!-- threading video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="threading-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/threading.mp4" type="video/mp4">
          </video>
          <p class="caption">Threading D2<sup>2</sup></p>
        </div>
      </div>

      <!-- square video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="square-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/square.mp4" type="video/mp4">
          </video>
          <p class="caption">Square D2<sup>1</sup></p>
        </div>
      </div>
    </div>

    <!-- Second Row -->
    <div class="columns is-multiline is-centered">
      <!-- Coffee D2 video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="coffee-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/coffee.mp4" type="video/mp4">
          </video>
          <p class="caption">Coffee D2<sup>1</sup></p>
        </div>
      </div>
      
      <!-- Hammer Cleanup video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="hammer_cleanup-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/hammer_cleanup.mp4" type="video/mp4">
          </video>
          <p class="caption">Hammer Cleanup D1<sup>1</sup></p>
        </div>
      </div>
      
      <!-- Push T video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="pusht-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/pusht.mp4" type="video/mp4">
          </video>
          <p class="caption">Push T<sup>2</sup></p>
        </div>
      </div>
      
      <!-- Cloth Folding video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="fold-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/fold.mp4" type="video/mp4">
          </video>
          <p class="caption">Cloth Folding<sup>3</sup></p>
        </div>
      </div>
      
      <!-- Object Covering video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="cover-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/cover.mp4" type="video/mp4">
          </video>
          <p class="caption">Object Covering<sup>3</sup></p>
        </div>
      </div>

      <!-- Box Closing video -->
      <div class="column is-2">
        <div class="content has-text-centered">
          <video id="close-video" autoplay muted loop playsinline width="100%">
            <source src="./static/videos/sim/close.mp4" type="video/mp4">
          </video>
          <p class="caption">Box Closing<sup>3</sup></p>
        </div>
      </div>
    </div>

    <!-- Space for text below videos -->
    <div class="content has-text-justified mt-4">
      <p class="has-text-centered" style="font-weight: 400; color: #666; font-family: 'Noto Sans', sans-serif; border-top: 1px dotted #e5e5e5; padding-top: 12px; margin-top: 20px; font-size: 0.95em;">
        <a href="https://robomimic.github.io/"><sup>1</sup>Robomimic</a> &nbsp;&nbsp;
        <a href="https://diffusion-policy.cs.columbia.edu/"><sup>2</sup>Diffusion Policy</a> &nbsp;&nbsp;
        <a href="https://github.com/yjy0625/equibot"><sup>3</sup>Equibot</a> &nbsp;&nbsp;
        <!-- Space for adding links later -->
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Real Robot Experiments</h2>
        <h2 class="title is-3">Effectiveness of Canonical Policy</h2>
        <h2 class="title is-4">Block Stacking</h2>
        <div class="content has-text-justified">
          <p>
            In the block stacking task, the robot stacks an I-shaped block onto a T-shaped block. On the left, under the original setup, the canonical policy performs reliably. On the right, even with changes in block color, the policy continues to execute the task accurately—showcasing robustness to appearance shifts.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="Block Stacking" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/BS.mp4" type="video/mp4">
          </video>
        </div>

        <h2 class="title is-4">Shoe Alignment</h2>
        <div class="content has-text-justified">
          <p>
            Next is the shoe alignment task, where the goal is to pick up the right shoe and align it side by side with the left shoe. The policy succeeds under the original setup on the left, and maintains high performance even when the shoe color is completely changed on the right, demonstrating strong appearance invariance.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="Shoe Alignment" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/SA.mp4" type="video/mp4">
          </video>
        </div>

        <h2 class="title is-4">Can Insertion</h2>
        <div class="content has-text-justified">
          <p>
            The can insertion task is more precision-demanding. The robot must pick up a can on the right and insert it into a hole on the left. Despite the challenge, canonical policy consistently succeeds under both the original and color-shifted settings, validating its grasping and placement accuracy.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="Can Insertion" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/CI.mp4" type="video/mp4">
          </video>
        </div>

        <h2 class="title is-4">Table Organzation</h2>
        <div class="content has-text-justified">
          <p>
            Table organization is the most complex task, requiring a sequence of precise operations: object placement and drawer manipulation. Canonical policy handles this long-horizon task effectively in both the original and color-variant setups, highlighting its capacity for robust, multi-step decision-making.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="Table Organzation" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/TO.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Generalization to Unseen Object Appearances</h2>
        <div class="content has-text-justified">
          <p>
            Beyond color variations, we also test shape generalization in the shoe alignment task. By introducing unseen objects—leather shoes and hiking shoes—with both appearance and geometric shifts, we test the policy’s ability to generalize. Despite these challenges, canonical policy achieves the highest alignment accuracy, demonstrating strong generalization to both shape and color shifts.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="Shoe Alignment" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/SA_Shape.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Robustness to Viewpoint Variations</h2>
        <div class="content has-text-justified">
          <p>
            We further evaluate the policy's SE(3) equivariance using a mobile UR5 platform with camera viewpoint shifts. As the camera gradually rotates from the original angle on the left to a significantly shifted one on the right, canonical policy maintains stable and accurate predictions, confirming its robustness to egocentric view changes.
          </p>
        </div>
        <h2 class="title is-5">Left-Angled View</h2>
        <div class="content has-text-centered">
          <video id="Left-Angled View" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/Ur Left.mp4" type="video/mp4">
          </video>
        </div>
        <h2 class="title is-5">Frontal View</h2>
        <div class="content has-text-centered">
          <video id="Frontal View" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/Ur Mid.mp4" type="video/mp4">
          </video>
        </div>
        <h2 class="title is-5">Right-Angled View</h2>
        <div class="content has-text-centered">
          <video id="Right-Angled" autoplay controls muted loop playsinline width="100%">
            <source src="./static/videos/Ur Right.mp4" type="video/mp4">
          </video>
        </div>
        <div class="content has-text-justified">
          <p>
            Failure case analysis: The performance drop in the Right-Angled View stems from the single-camera setup, where large viewpoint shifts lead to significantly different point clouds. These new observations often include previously unseen regions, making it difficult for the policy to generalize. In contrast, under small-angle shifts (Frontal View), there is substantial overlap between training and test point clouds, allowing the canonical policy to exploit geometric equivariance and consistently map inputs to the same canonical pose. 
          </p>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title is-3 has-text-centered">BibTeX</h2>
    <pre style="background: #f8f8f8; border-radius: 6px; box-shadow: 0 1px 6px rgba(0,0,0,0.05); font-family: 'Castoro', monospace;"><code>
      @article{zhang2025canonical,
        title={Canonical Policy: Learning Canonical 3D Representation for Equivariant Policy},
        author={Zhang, Zhiyuan and Xu, Zhengtong and Lakamsani, Jai Nanda and She, Yu},
        journal={arXiv preprint arXiv:2505.18474},
        year={2025}
      }
    </code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/ZhangZhiyuanZhang" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            The template of this website is adapted from <a
              href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
